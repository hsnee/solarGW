{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "source": [
    "# Solar Gravitational Waves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "source": [
    "This is a tutorial on analysing and creating an upper limit on gravitational waves from the Sun."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "source": [
    "We will use a sample hdf5 containing high-quality data from the 6th Science Run of LIGO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "hide_input": true,
    "hide_output": true,
    "run_control": {
     "marked": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"https://losc.ligo.org/archive/data/S6/931135488/L-L1_LOSC_4_V1-931188736-4096.hdf5\">You can download it here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<a href=\"https://losc.ligo.org/archive/data/S6/931135488/L-L1_LOSC_4_V1-931188736-4096.hdf5\">You can download it here</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "source": [
    "for our sample: **start time = 931188736, end time = 931192832 **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "source": [
    "You can download more data from the LIGO S6 and S5, which are available publicly at: https://losc.ligo.org/data/. More data makes for better results (will discuss what this means later) but becomes computationally heavy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "source": [
    "Now, to read in the data, we need the [gwpy](http://gwpy.github.io) package "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "source": [
    "to ensure you have the right packages, do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "hide_input": false,
    "hide_output": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied (use --upgrade to upgrade): gwpy in /Users/myhome/anaconda/lib/python2.7/site-packages\n",
      "Requirement already satisfied (use --upgrade to upgrade): numpy>=1.7 in /Users/myhome/anaconda/lib/python2.7/site-packages (from gwpy)\n",
      "Requirement already satisfied (use --upgrade to upgrade): scipy>=0.16.0 in /Users/myhome/anaconda/lib/python2.7/site-packages (from gwpy)\n",
      "Requirement already satisfied (use --upgrade to upgrade): astropy>=1.0 in /Users/myhome/anaconda/lib/python2.7/site-packages (from gwpy)\n",
      "Requirement already satisfied (use --upgrade to upgrade): matplotlib>=1.3.0 in /Users/myhome/anaconda/lib/python2.7/site-packages (from gwpy)\n",
      "Requirement already satisfied (use --upgrade to upgrade): six>=1.5 in /Users/myhome/anaconda/lib/python2.7/site-packages (from gwpy)\n",
      "Requirement already satisfied (use --upgrade to upgrade): python-dateutil in /Users/myhome/anaconda/lib/python2.7/site-packages (from gwpy)\n",
      "Requirement already satisfied (use --upgrade to upgrade): pytz in /Users/myhome/anaconda/lib/python2.7/site-packages (from matplotlib>=1.3.0->gwpy)\n",
      "Requirement already satisfied (use --upgrade to upgrade): cycler in /Users/myhome/anaconda/lib/python2.7/site-packages (from matplotlib>=1.3.0->gwpy)\n",
      "Requirement already satisfied (use --upgrade to upgrade): pyparsing!=2.0.4,>=1.5.6 in /Users/myhome/anaconda/lib/python2.7/site-packages (from matplotlib>=1.3.0->gwpy)\n",
      "Requirement already satisfied (use --upgrade to upgrade): numpy in /Users/myhome/anaconda/lib/python2.7/site-packages\n",
      "Requirement already satisfied (use --upgrade to upgrade): astropy in /Users/myhome/anaconda/lib/python2.7/site-packages\n",
      "Requirement already satisfied (use --upgrade to upgrade): matplotlib in /Users/myhome/anaconda/lib/python2.7/site-packages\n",
      "Requirement already satisfied (use --upgrade to upgrade): scipy in /Users/myhome/anaconda/lib/python2.7/site-packages\n",
      "Requirement already satisfied (use --upgrade to upgrade): python-dateutil in /Users/myhome/anaconda/lib/python2.7/site-packages (from matplotlib)\n",
      "Requirement already satisfied (use --upgrade to upgrade): pytz in /Users/myhome/anaconda/lib/python2.7/site-packages (from matplotlib)\n",
      "Requirement already satisfied (use --upgrade to upgrade): cycler in /Users/myhome/anaconda/lib/python2.7/site-packages (from matplotlib)\n",
      "Requirement already satisfied (use --upgrade to upgrade): pyparsing!=2.0.4,>=1.5.6 in /Users/myhome/anaconda/lib/python2.7/site-packages (from matplotlib)\n",
      "Requirement already satisfied (use --upgrade to upgrade): six>=1.5 in /Users/myhome/anaconda/lib/python2.7/site-packages (from python-dateutil->matplotlib)\n",
      "Password:\n"
     ]
    }
   ],
   "source": [
    "!pip install --pre --user gwpy;\n",
    "!pip install numpy astropy matplotlib scipy \n",
    "!sudo ports install lal lalapps pylal glue lalframe # You need MacPorts to use this on a Mac, if you're using Linux or Windows, follow the installation instructions at ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's import some useful packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "hide_input": false,
    "hide_output": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name units",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-bb8fce07e7fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogsumexp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgwpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeSeries\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mTimeSeries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'matplotlib inlinex'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/myhome/anaconda/lib/python2.7/site-packages/gwpy/timeseries/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0m__author__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Duncan Macleod <duncan.macleod@ligo.org>\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtimeseries\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mstatevector\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/myhome/anaconda/lib/python2.7/site-packages/gwpy/timeseries/core.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m                             nds2.channel.CHANNEL_TYPE_STATIC)\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mArray2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetector\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mChannel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mChannelList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatafind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/myhome/anaconda/lib/python2.7/site-packages/gwpy/data/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mglue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mCache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCacheEntry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0marray2d\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mseries\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/myhome/anaconda/lib/python2.7/site-packages/gwpy/data/array.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetector\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChannel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparse_unit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_gps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/myhome/anaconda/lib/python2.7/site-packages/gwpy/detector/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeps\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwith_import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mchannel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name units"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import glue, gwpy, astroapy\n",
    "from astropy.coordinates import get_sun\n",
    "import astropy, h5py, os\n",
    "import astropy.time as Time\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from scipy.signal import butter, filtfilt\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import logsumexp\n",
    "import gwpy.timeseries.TimeSeries as TimeSeries\n",
    "%matplotlib inlinex\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Antenna Respone \n",
    "def antenna_response( gpsTime, ra, dec, psi, det ):\n",
    "    from types import StringType, FloatType\n",
    "    import lal\n",
    "    import numpy as np\n",
    "    from types import StringType, FloatType\n",
    "\n",
    "    # create detector-name map\n",
    "    detMap = {'H1': lal.LALDetectorIndexLHODIFF, \\\n",
    "            'H2': lal.LALDetectorIndexLHODIFF, \\\n",
    "            'L1': lal.LALDetectorIndexLLODIFF, \\\n",
    "            'G1': lal.LALDetectorIndexGEO600DIFF, \\\n",
    "            'V1': lal.LALDetectorIndexVIRGODIFF, \\\n",
    "            'T1': lal.LALDetectorIndexTAMA300DIFF, \\\n",
    "            'AL1': lal.LALDetectorIndexLLODIFF, \\\n",
    "            'AH1': lal.LALDetectorIndexLHODIFF, \\\n",
    "            'AV1': lal.LALDetectorIndexVIRGODIFF}\n",
    "\n",
    "    try:\n",
    "        detector=detMap[det]\n",
    "    except KeyError:\n",
    "        raise ValueError, \"ERROR. Key %s is not a valid detector name.\" % (det)\n",
    "\n",
    "    # get detector\n",
    "    detval = lal.CachedDetectors[detector]\n",
    "    response = detval.response\n",
    "\n",
    "    # check if gpsTime is just a float or int, and if so convert into an array\n",
    "    if isinstance(gpsTime, float) or isinstance(gpsTime, int):\n",
    "        gpsTime = np.array([gpsTime])\n",
    "    else: # make sure it's a numpy array\n",
    "        gpsTime = np.copy(gpsTime)\n",
    "\n",
    "    # if gpsTime is a list of regularly spaced values then use ComputeDetAMResponseSeries\n",
    "    if len(gpsTime) == 1 or np.unique(np.diff(gpsTime)).size == 1:\n",
    "        gpsStart = lal.LIGOTimeGPS( gpsTime[0] )\n",
    "        dt = 0.\n",
    "    if len(gpsTime) > 1:\n",
    "        dt = gpsTime[1]-gpsTime[0]\n",
    "        fp, fc = lal.ComputeDetAMResponseSeries(response, ra, dec, psi, gpsStart, dt, len(gpsTime))\n",
    "\n",
    "    # return elements from Time Series\n",
    "        return fp.data.data, fc.data.data\n",
    "    \n",
    "    else: # we'll have to work out the value at each point in the time series\n",
    "        fp = np.zeros(len(gpsTime))\n",
    "        fc = np.zeros(len(gpsTime))\n",
    "\n",
    "    for i in range(len(gpsTime)):\n",
    "        gps = lal.LIGOTimeGPS( gpsTime[i] )\n",
    "        gmst_rad = lal.GreenwichMeanSiderealTime(gps)\n",
    "\n",
    "        # actual computation of antenna factors\n",
    "        fp[i], fc[i] = lal.ComputeDetAMResponse(response, ra, dec, psi, gmst_rad)\n",
    "    fp = fp[0]\n",
    "    fc = fc[0]\n",
    "    return fp, fc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Analysis\n",
    "# code to add up the probability for a month or a week, prints the duration, and plots the cumulative probability to infer the upper limit at x% confidence. Prints the upper limit on h0 at 95% confidence\n",
    "def plotdist(starttime,endtime):\n",
    "\t# starttime and endtime should be in format 'week'+str(i) or 'month'+str(i) only.\n",
    "\t# In the near future it will take 'all' as starttime and endtime to plot the entire data.\n",
    "\timport numpy as np\n",
    "\tfrom matplotlib.backends.backend_pdf import PdfPages\n",
    "\timport matplotlib.pyplot as plt\n",
    "\timport os\n",
    "\tfname =\t'probdist_cumulative.pdf'\n",
    "\tif os.path.exists('/home/spxha/')==True:\n",
    "\t\tpathtointersect = '/home/spxha/solarGW/intersect_old.txt'\n",
    "\telse:\n",
    "\t\tpathtointersect = '../../../intersect_old.txt'\n",
    "\ttimearray = np.array(np.loadtxt(pathtointersect,dtype='f8'))\n",
    "\tStartTimes = timearray[:,0]\n",
    "\tEndTimes   = timearray[:,1]\n",
    "\tif starttime=='all' and endtime=='all':\n",
    "\t\tstarttime = 931076896.0\n",
    "\t\tendtime   = 971614889.0\n",
    "\tduration = 0\n",
    "\tnewStartTimes = StartTimes[(np.abs(StartTimes-starttime)).argmin():(np.abs(EndTimes-endtime)).argmin()]\n",
    "\tnewEndTimes   =   EndTimes[(np.abs(StartTimes-starttime)).argmin():(np.abs(EndTimes-endtime)).argmin()]\n",
    "\tp_array,h0_array = [[[0 for _ in range(30)] for _ in range(len(newStartTimes))] for _ in range(2)]\n",
    "\tj = 0\n",
    "\tfor i in range(len(newStartTimes)):\n",
    "\t\tpathi = 'p'+str(int(newStartTimes[i]))+'.txt'\n",
    "\t\tif os.path.exists(pathi)==True:\n",
    "\t\t\tj +=1\n",
    "\t\t\tprint i\n",
    "\t\t\tp_array[i]  = np.array(np.loadtxt('p'+str(int(newStartTimes[i]))+'.txt',dtype='float'))\n",
    "\t\t\th0_array[i] = np.array(np.loadtxt('h0'+str(int(newStartTimes[i]))+'.txt',dtype='float'))\n",
    "\t\t\tduration += newEndTimes[i]-newStartTimes[i] - 150\n",
    "\t\telse:\n",
    "\t\t\tpass\n",
    "\tprint j\n",
    "\tp_sum_array = [0.0 for _ in range(30)]\n",
    "\tp_sum_array = np.array(p_sum_array)\n",
    "\th0_array = np.array(h0_array)\n",
    "\tprint p_array[1]\n",
    "\tp_array = np.array(p_array)\n",
    "\tfor i in range(len(p_array)-1):\n",
    "\t\tp_sum_array += p_array[i+1]\n",
    "\th0_mean_array = h0_array.mean(0)\n",
    "\tp = np.exp(p_sum_array-np.max(p_sum_array))\n",
    "\tprint h0_mean_array,p\n",
    "\n",
    "\t# Making a cumulative plot to get the 95% value.\n",
    "\tprob = [0 for _ in range(len(p))]\n",
    "\tfor i in range(30):\n",
    "\t\td = [0 for _ in range(i+1)]\n",
    "\t\tprint i\n",
    "\t\tfor j in range(i+1):\n",
    "\t\t\tprint i,j\n",
    "\t\t\td[j] = p[i-j]\n",
    "\t\t\tprint d[j]\n",
    "\t\tprob[i] = np.sum(d)\n",
    "\t\tprint prob[i]\n",
    "\tprob = prob/(np.max(prob))\n",
    "\tprint prob\n",
    "\t# plot the distribution\n",
    "\twith PdfPages(fname) as pdf:\n",
    "\t\tfig1 = plt.figure()\n",
    "\t\tplt.plot(h0_mean_array,prob,'+')\n",
    "\t\tplt.title('Cumulative probability for '+str(int(duration/3600))+' hours')\n",
    "\t\tplt.xlabel(r'$h_0$')\n",
    "\t\tplt.ylabel('Normalised cumulative probability')\n",
    "\t\tpdf.savefig(fig1)\n",
    "\t\tplt.close()\n",
    "\tprint (h0_mean_array[10]+h0_mean_array[11])/2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsampling \n",
    "The data that we have now has 4xxx data points per second, however our highest frequency is 150 Hz, so there is a lot of unnecessary information. We can make the processing time shorter by downsampling the data, such that we get 512 data points per second. This will still include all the useful data. \n",
    "\n",
    "This step is not essential, but will make your code run 32 times faster, with no loss of (useful) information!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "hide_output": true,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Xspacing' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-0bebdf4aeb13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Downsampling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mXspacing\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mXspacing\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnum_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdurationH\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mXspacing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnewtdelay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewtimeL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewtimeH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewstrainH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewstrainL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Xspacing' is not defined"
     ]
    }
   ],
   "source": [
    "# Downsampling\n",
    "Xspacing   = Xspacing*8\n",
    "num_points = int(durationH/Xspacing)\n",
    "newtdelay, newtimeL, newtimeH, newstrainH, newstrainL = [[0 for _ in range(num_points)] for _ in range(5)]\n",
    "for i in range(num_points):\n",
    "\tj = 8*i + 4\n",
    "\tnewstrainH[i] = np.mean(strainH[j-4:j+4])\n",
    "\tnewstrainL[i] = np.mean(strainL[j-4:j+4])\n",
    "\tnewtimeH[i]   = timeH[j]\n",
    "\tnewtimeL[i]   = timeL[j]\n",
    "\tnewtdelay[i]  = tdelay[j]\n",
    "newstrainH = newstrainH[76800:len(newstrainH)]\n",
    "newstrainL = newstrainL[76800:len(newstrainL)]\n",
    "newtimeH   = newtimeH[76800:len(newtimeH)]\n",
    "newtimeL   = newtimeL[76800:len(newtimeL)]\n",
    "newtdelay  = newtdelay[76800:len(newtdelay)]\n",
    "starttime  = starttime + 150\n",
    "durationH  = int(newtimeH[-1]) - int(newtimeH[0])\n",
    "num_points = int(durationH/Xspacing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "hide_output": true,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'endtime' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-c24efb5a9b1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Reading in data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdurationH\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mendtime\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstarttime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mXspacing\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0;36m2.44140625E-4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mstrainH\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0mTimeSeries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'S6framesH1.lcf'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchannel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'H1:LDAS-STRAIN'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstarttime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mendtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mstrainL\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0mTimeSeries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'S6framesL1.lcf'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchannel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'L1:LDAS-STRAIN'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstarttime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mendtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'endtime' is not defined"
     ]
    }
   ],
   "source": [
    "# Reading in data\n",
    "durationH    = endtime - starttime\n",
    "Xspacing     = 2.44140625E-4\n",
    "strainH      = TimeSeries.read('S6framesH1.lcf',channel='H1:LDAS-STRAIN', start=starttime, end=endtime)\n",
    "strainL      = TimeSeries.read('S6framesL1.lcf',channel='L1:LDAS-STRAIN', start=starttime, end=endtime)\n",
    "num_points   = int(durationH/Xspacing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering\n",
    "Due to the nature of the noise LIGO is subjected to, its sensitivity varies with frequency. The most sensitive range of the LIGO detectors is around 100 to 150 Hz. This can be seen from the sensitivity curves (aka noise spectra) below. In addition to this, we have other sources of noise, such as ... which contributes to noise in a short-frequency range. Both types of noise were filtered out in the search. \n",
    "\n",
    "[images] # probably use seaborn\n",
    "\n",
    "The following plots show the effects of bandpass filtering, and notch filtering:\n",
    "\n",
    "[images]\n",
    "\n",
    "Let's first define a function that does this filtering. We're going to use scipy's filters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [],
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Data filtering. Functions courtesy of LSC: \n",
    "\n",
    "def iir_bandstops(fstops, fs, order=4):\n",
    "    import numpy as np\n",
    "    from scipy.signal import iirdesign, zpk2tf, freqz\n",
    "    nyq = 0.5 * fs\n",
    "    # Zeros zd, poles pd, and gain kd for the digital filter\n",
    "    zd = np.array([])\n",
    "    pd = np.array([])\n",
    "    kd = 1\n",
    "\n",
    "    # Notches\n",
    "    for fstopData in fstops:\n",
    "        fstop = fstopData[0]\n",
    "        df = fstopData[1]\n",
    "        df2 = fstopData[2]\n",
    "        low = (fstop - df) / nyq\n",
    "        high = (fstop + df) / nyq\n",
    "        low2 = (fstop - df2) / nyq\n",
    "        high2 = (fstop + df2) / nyq\n",
    "        z, p, k = iirdesign([low,high], [low2,high2], gpass=1, gstop=6,\n",
    "                            ftype='ellip', output='zpk')\n",
    "        zd = np.append(zd,z)\n",
    "        pd = np.append(pd,p)\n",
    "\n",
    "    # Set gain to one at 100 Hz...better not notch there\n",
    "    bPrelim,aPrelim = zpk2tf(zd, pd, 1)\n",
    "    outFreq, outg0 = freqz(bPrelim, aPrelim, 100/nyq)\n",
    "\n",
    "    # Return the numerator and denominator of the digital filter\n",
    "    b,a = zpk2tf(zd,pd,k)\n",
    "    return b, a\n",
    "\n",
    "def get_filter_coefs(det,fs=4096):\n",
    "    from scipy.signal import butter, filtfilt, iirdesign, zpk2tf, freqz\n",
    "    import numpy as np\n",
    "\n",
    "    # assemble the filter b,a coefficients:\n",
    "    coefs = []\n",
    "\n",
    "    # bandpass filter parameters\n",
    "    lowcut = 100\n",
    "    highcut = 150\n",
    "    order = 4\n",
    "\n",
    "    # bandpass filter coefficients\n",
    "    nyq = 0.5*fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    bb, ab = butter(order, [low, high], btype='band')\n",
    "    coefs.append((bb,ab))\n",
    "\n",
    "    # Frequencies of notches at known instrumental spectral line frequencies.\n",
    "    # You can see these lines in the ASD above, so it is straightforward to make this list.\n",
    "    if det=='L1':\n",
    "        notchesAbsolute = np.array([120.0, 139.94, 145.06, 108.992])\n",
    "    elif det=='H1':\n",
    "        notchesAbsolute = np.array([120.0, 139.95, 140.41, 108.992])\n",
    "    else:\n",
    "        print 'Error: Detector can only be H1 or L1'\n",
    "        exit()\n",
    "    # notch filter coefficients:\n",
    "    for notchf in notchesAbsolute:\n",
    "        bn, an = iir_bandstops(np.array([[notchf,1,0.1]]), fs, order=4)\n",
    "        coefs.append((bn,an))\n",
    "\n",
    "    return coefs\n",
    "\n",
    "# and then define the filter function:\n",
    "def filter_data(data_in,coefs):\n",
    "    import scipy\n",
    "    import numpy as np\n",
    "    from scipy.signal import filtfilt\n",
    "    data = data_in.copy()\n",
    "    for coef in coefs:\n",
    "        b,a = coef\n",
    "        # filtfilt applies a linear filter twice, once forward and once backwards.\n",
    "        # The combined filter has linear phase.\n",
    "        data = filtfilt(b, a, data)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's those functions on our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "hide_output": true,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'strainL' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-370826fe5920>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcoefsL\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mget_filter_coefs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'L1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcoefsH\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mget_filter_coefs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'H1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mstrainL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrainL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcoefsL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mstrainH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrainH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcoefsH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtimeH\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstarttime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXspacing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'strainL' is not defined"
     ]
    }
   ],
   "source": [
    "# Filtering\n",
    "coefsL  = get_filter_coefs('L1')\n",
    "coefsH  = get_filter_coefs('H1')\n",
    "strainL = filter_data(strainL,coefsL)\n",
    "strainH = filter_data(strainH,coefsH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check that this is working fine, we can plot a small sample of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Synchronising the Detectors\n",
    "\n",
    "Gravitational waves travel at the speed of light. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "hide_output": true,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'oldstarttime' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-c854b17435bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Write to a file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'p'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moldstarttime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'h0'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moldstarttime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh0_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'oldstarttime' is not defined"
     ]
    }
   ],
   "source": [
    "# Write to a file\n",
    "np.savetxt('p'+str(oldstarttime)+'.txt',p)\n",
    "np.savetxt('h0'+str(oldstarttime)+'.txt',h0_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# code to add up the probability for a month or a week, prints the duration, and plots the probability distribution\n",
    "def plotdist(starttime,endtime):\n",
    "\t# starttime and endtime should be in format 'week'+str(i) or 'month'+str(i) only.\n",
    "\t# In the near future it will take 'all' as starttime and endtime to plot the entire data.\n",
    "\timport numpy as np\n",
    "\tfrom matplotlib.backends.backend_pdf import PdfPages\n",
    "\timport matplotlib.pyplot as plt\n",
    "\timport os\n",
    "\tfname =\t'probdist_'+starttime+'_'+endtime+'.pdf'\n",
    "\tif os.path.exists('/home/spxha/')==True:\n",
    "\t\tpathtointersect = '/home/spxha/solarGW/intersect_old.txt'\n",
    "\telse:\n",
    "\t\tpathtointersect = '../../../intersect_old.txt'\n",
    "\ttimearray = np.array(np.loadtxt(pathtointersect,dtype='f8'))\n",
    "\tStartTimes = timearray[:,0]\n",
    "\tEndTimes   = timearray[:,1]\n",
    "\tif starttime=='all' and endtime=='all':\n",
    "\t\tstarttime = 931076896.0\n",
    "\t\tendtime   = 971614889.0\n",
    "\tduration = 0\n",
    "\tnewStartTimes = StartTimes[(np.abs(StartTimes-starttime)).argmin():(np.abs(EndTimes-endtime)).argmin()]\n",
    "\tnewEndTimes   =   EndTimes[(np.abs(StartTimes-starttime)).argmin():(np.abs(EndTimes-endtime)).argmin()]\n",
    "\tp_array,h0_array = [[[0 for _ in range(30)] for _ in range(len(newStartTimes))] for _ in range(2)]\n",
    "\tj = 0\n",
    "\tfor i in range(len(newStartTimes)):\n",
    "\t\tpathi = 'p'+str(int(newStartTimes[i]))+'.txt'\n",
    "\t\tif os.path.exists(pathi)==True:\n",
    "\t\t\tj +=1\n",
    "\t\t\tprint i\n",
    "\t\t\tp_array[i]  = np.array(np.loadtxt('p'+str(int(newStartTimes[i]))+'.txt',dtype='float'))\n",
    "\t\t\th0_array[i] = np.array(np.loadtxt('h0'+str(int(newStartTimes[i]))+'.txt',dtype='float'))\n",
    "\t\t\tduration += newEndTimes[i]-newStartTimes[i] - 150\n",
    "\t\telse:\n",
    "\t\t\tpass\n",
    "\tprint j\n",
    "\tp_sum_array = [0.0 for _ in range(30)]\n",
    "\tp_sum_array = np.array(p_sum_array)\n",
    "\th0_array = np.array(h0_array)\n",
    "\tprint p_array[1]\n",
    "\tp_array = np.array(p_array)\n",
    "\tfor i in range(len(p_array)-1):\n",
    "\t\tp_sum_array += p_array[i+1]\n",
    "\th0_mean_array = h0_array.mean(0)\n",
    "\tp = np.exp(p_sum_array-np.max(p_sum_array))\n",
    "\tprint h0_mean_array,p\n",
    "\t# plot the distribution\n",
    "\twith PdfPages(fname) as pdf:\n",
    "\t\tfig1 = plt.figure()\n",
    "\t\tplt.plot(h0_mean_array,p)\n",
    "\t\tplt.plot(h0_mean_array,p,'+')\n",
    "\n",
    "#\t\tplt.title('Probability Distribution for '+str(int(duration/(3600)))+' hours')\n",
    "\t\tplt.xlabel(r'$h_0$')\n",
    "\t\tplt.ylabel('Normalised probability')\n",
    "\t\tpdf.savefig(fig1)\n",
    "\t\tplt.close()\n",
    "\n",
    "# code to add up the probability for a month or a week, prints the duration, and plots the cumulative probability to infer the upper limit at x% confidence. Prints the upper limit on h0 at 95% confidence\n",
    "def cumulative(starttime,endtime):\n",
    "\t# starttime and endtime should be in format 'week'+str(i) or 'month'+str(i) only.\n",
    "\t# In the near future it will take 'all' as starttime and endtime to plot the entire data.\n",
    "\timport numpy as np\n",
    "\tfrom matplotlib.backends.backend_pdf import PdfPages\n",
    "\timport matplotlib.pyplot as plt\n",
    "\timport os\n",
    "\tfname =\t'probdist_cumulative.pdf'\n",
    "\tif os.path.exists('/home/spxha/')==True:\n",
    "\t\tpathtointersect = '/home/spxha/solarGW/intersect_old.txt'\n",
    "\telse:\n",
    "\t\tpathtointersect = '../../../intersect_old.txt'\n",
    "\ttimearray = np.array(np.loadtxt(pathtointersect,dtype='f8'))\n",
    "\tStartTimes = timearray[:,0]\n",
    "\tEndTimes   = timearray[:,1]\n",
    "\tif starttime=='all' and endtime=='all':\n",
    "\t\tstarttime = 931076896.0\n",
    "\t\tendtime   = 971614889.0\n",
    "\tduration = 0\n",
    "\tnewStartTimes = StartTimes[(np.abs(StartTimes-starttime)).argmin():(np.abs(EndTimes-endtime)).argmin()]\n",
    "\tnewEndTimes   =   EndTimes[(np.abs(StartTimes-starttime)).argmin():(np.abs(EndTimes-endtime)).argmin()]\n",
    "\tp_array,h0_array = [[[0 for _ in range(30)] for _ in range(len(newStartTimes))] for _ in range(2)]\n",
    "\tj = 0\n",
    "\tfor i in range(len(newStartTimes)):\n",
    "\t\tpathi = 'p'+str(int(newStartTimes[i]))+'.txt'\n",
    "\t\tif os.path.exists(pathi)==True:\n",
    "\t\t\tj +=1\n",
    "\t\t\tprint i\n",
    "\t\t\tp_array[i]  = np.array(np.loadtxt('p'+str(int(newStartTimes[i]))+'.txt',dtype='float'))\n",
    "\t\t\th0_array[i] = np.array(np.loadtxt('h0'+str(int(newStartTimes[i]))+'.txt',dtype='float'))\n",
    "\t\t\tduration += newEndTimes[i]-newStartTimes[i] - 150\n",
    "\t\telse:\n",
    "\t\t\tpass\n",
    "\tprint j\n",
    "\tp_sum_array = [0.0 for _ in range(30)]\n",
    "\tp_sum_array = np.array(p_sum_array)\n",
    "\th0_array = np.array(h0_array)\n",
    "\tprint p_array[1]\n",
    "\tp_array = np.array(p_array)\n",
    "\tfor i in range(len(p_array)-1):\n",
    "\t\tp_sum_array += p_array[i+1]\n",
    "\th0_mean_array = h0_array.mean(0)\n",
    "\tp = np.exp(p_sum_array-np.max(p_sum_array))\n",
    "\tprint h0_mean_array,p\n",
    "\n",
    "\t# Making a cumulative plot to get the 95% value.\n",
    "\tprob = [0 for _ in range(len(p))]\n",
    "\tfor i in range(30):\n",
    "\t\td = [0 for _ in range(i+1)]\n",
    "\t\tprint i\n",
    "\t\tfor j in range(i+1):\n",
    "\t\t\tprint i,j\n",
    "\t\t\td[j] = p[i-j]\n",
    "\t\t\tprint d[j]\n",
    "\t\tprob[i] = np.sum(d)\n",
    "\t\tprint prob[i]\n",
    "\tprob = prob/(np.max(prob))\n",
    "\tprint prob\n",
    "\t# plot the distribution\n",
    "\twith PdfPages(fname) as pdf:\n",
    "\t\tfig1 = plt.figure()\n",
    "\t\tplt.plot(h0_mean_array,prob,'+')\n",
    "#\t\tplt.title('Cumulative probability for '+str(int(duration/3600))+' hours')\n",
    "\t\tplt.xlabel(r'$h_0$')\n",
    "\t\tplt.ylabel('Normalised cumulative probability')\n",
    "\t\tpdf.savefig(fig1)\n",
    "\t\tplt.close()\n",
    "\tprint (h0_mean_array[10]+h0_mean_array[11])/2\n",
    "\n",
    "# code to add up the probability for a month or a week, then find the evidence value.\n",
    "# note to self --> should merge this with distplot.py and cumulative.py\n",
    "def evidence(starttime,endtime):\n",
    "\t# starttime and endtime should be in format 'week'+str(i) or 'month'+str(i) only.\n",
    "\t# In the near future it will take 'all' as starttime and endtime to plot the entire data.\n",
    "\timport numpy as np\n",
    "\tfrom matplotlib.backends.backend_pdf import PdfPages\n",
    "\timport matplotlib.pyplot as plt\n",
    "\timport os\n",
    "\tfname =\t'probdist_'+starttime+'_'+endtime+'.pdf'\n",
    "\tif os.path.exists('/home/spxha/')==True:\n",
    "\t\tpathtointersect = '/home/spxha/solarGW/intersect_old.txt'\n",
    "\telse:\n",
    "\t\tpathtointersect = '../../../intersect_old.txt'\n",
    "\ttimearray = np.array(np.loadtxt(pathtointersect,dtype='f8'))\n",
    "\tStartTimes = timearray[:,0]\n",
    "\tEndTimes   = timearray[:,1]\n",
    "\tif starttime=='all' and endtime=='all':\n",
    "\t\tstarttime = 931076896.0\n",
    "\t\tendtime   = 971614889.0\n",
    "\tduration = 0\n",
    "\tnewStartTimes = StartTimes[(np.abs(StartTimes-starttime)).argmin():(np.abs(EndTimes-endtime)).argmin()]\n",
    "\tnewEndTimes   =   EndTimes[(np.abs(StartTimes-starttime)).argmin():(np.abs(EndTimes-endtime)).argmin()]\n",
    "\tp_array,h0_array = [[[0 for _ in range(30)] for _ in range(len(newStartTimes))] for _ in range(2)]\n",
    "\tj = 0\n",
    "\tfor i in range(len(newStartTimes)):\n",
    "\t\tpathi = 'p'+str(int(newStartTimes[i]))+'.txt'\n",
    "\t\tif os.path.exists(pathi)==True:\n",
    "\t\t\tj +=1\n",
    "\t\t\tprint i\n",
    "\t\t\tp_array[i]  = np.array(np.loadtxt('p'+str(int(newStartTimes[i]))+'.txt',dtype='float'))\n",
    "\t\t\th0_array[i] = np.array(np.loadtxt('h0'+str(int(newStartTimes[i]))+'.txt',dtype='float'))\n",
    "\t\t\tduration += newEndTimes[i]-newStartTimes[i] - 150\n",
    "\t\telse:\n",
    "\t\t\tpass\n",
    "\tprint j\n",
    "\tp_sum_array = [0.0 for _ in range(30)]\n",
    "\tp_sum_array = np.array(p_sum_array)\n",
    "\th0_array = np.array(h0_array)\n",
    "\tprint p_array[1]\n",
    "\tp_array = np.array(p_array)\n",
    "\tfor i in range(len(p_array)-1):\n",
    "\t\tp_sum_array += p_array[i+1]\n",
    "\th0_mean_array = h0_array.mean(0)\n",
    "\tp = np.exp(p_sum_array-np.max(p_sum_array))\n",
    "\tprint h0_mean_array,p\n",
    "\n",
    "\t# use np.trapz to integrate the plot to find the evidence.\n",
    "\tprint 'Z = ', np.trapz(p,x=h0_mean_array)\n",
    "\t# [out49,174]: Z =  2.89410498091e-28\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
